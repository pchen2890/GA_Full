{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting shots made per game by Kobe Bryant\n",
    "\n",
    "In this lab you'll be using regularization techniques Ridge, Lasso, and Elastic Net to try and predict well how many shots Kobe Bryant made per game in his career.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/basilbeirouti/miniconda3/envs/dsienv/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kobe = pd.read_csv('../starter/kobe_superwide_games.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Examine the data\n",
    "\n",
    "- How many columns are there?\n",
    "- Infer what the observations (rows) and columns represent.\n",
    "- Why is this data that regularization might be particularly useful for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: 645\n"
     ]
    }
   ],
   "source": [
    "print 'Columns:', len(kobe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'SHOTS_MADE', u'AWAY_GAME', u'SEASON_OPPONENT:atl:1996-97',\n",
      "       u'SEASON_OPPONENT:atl:1997-98', u'SEASON_OPPONENT:atl:1999-00',\n",
      "       u'SEASON_OPPONENT:atl:2000-01', u'SEASON_OPPONENT:atl:2001-02',\n",
      "       u'SEASON_OPPONENT:atl:2002-03', u'SEASON_OPPONENT:atl:2003-04',\n",
      "       u'SEASON_OPPONENT:atl:2004-05', u'SEASON_OPPONENT:atl:2005-06',\n",
      "       u'SEASON_OPPONENT:atl:2006-07', u'SEASON_OPPONENT:atl:2007-08',\n",
      "       u'SEASON_OPPONENT:atl:2008-09', u'SEASON_OPPONENT:atl:2009-10',\n",
      "       u'SEASON_OPPONENT:atl:2010-11', u'SEASON_OPPONENT:atl:2011-12',\n",
      "       u'SEASON_OPPONENT:atl:2012-13', u'SEASON_OPPONENT:atl:2013-14',\n",
      "       u'SEASON_OPPONENT:atl:2014-15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print kobe.columns[0:20]\n",
    "\n",
    "# The columns are various statistics for each game. \n",
    "# There is a column SHOTS_MADE that will be our target variable for prediction\n",
    "# This is good for regularization because there are so many columns (feature selection)\n",
    "# and many of the columns represent similar things (multicollinearity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Make predictor and target variables. Normalize the predictors.\n",
    "\n",
    "Why is normalization necessary for regularized regressions?\n",
    "\n",
    "There is a class in sklearn.preprocessing called `StandardScaler`. Look it up and figure out how to use it to normalize your predictor matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = kobe.SHOTS_MADE.values\n",
    "X = kobe.iloc[:,1:]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X)\n",
    "Xn = ss.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWAY_GAME</th>\n",
       "      <th>SEASON_OPPONENT:atl:1996-97</th>\n",
       "      <th>SEASON_OPPONENT:atl:1997-98</th>\n",
       "      <th>SEASON_OPPONENT:atl:1999-00</th>\n",
       "      <th>SEASON_OPPONENT:atl:2000-01</th>\n",
       "      <th>SEASON_OPPONENT:atl:2001-02</th>\n",
       "      <th>SEASON_OPPONENT:atl:2002-03</th>\n",
       "      <th>SEASON_OPPONENT:atl:2003-04</th>\n",
       "      <th>SEASON_OPPONENT:atl:2004-05</th>\n",
       "      <th>SEASON_OPPONENT:atl:2005-06</th>\n",
       "      <th>...</th>\n",
       "      <th>ACTION_TYPE:tip_layup_shot</th>\n",
       "      <th>ACTION_TYPE:tip_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_bank_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_fadeaway_bank_jump_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_fadeaway_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_finger_roll_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_hook_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_jump_shot</th>\n",
       "      <th>SEASON_GAME_NUMBER</th>\n",
       "      <th>CAREER_GAME_NUMBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "      <td>1.558000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.365815e-17</td>\n",
       "      <td>1.368182e-17</td>\n",
       "      <td>1.368182e-17</td>\n",
       "      <td>1.368182e-17</td>\n",
       "      <td>9.121216e-18</td>\n",
       "      <td>9.121216e-18</td>\n",
       "      <td>9.121216e-18</td>\n",
       "      <td>1.368182e-17</td>\n",
       "      <td>1.368182e-17</td>\n",
       "      <td>1.482198e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.560608e-18</td>\n",
       "      <td>-4.560608e-17</td>\n",
       "      <td>-1.824243e-17</td>\n",
       "      <td>9.121216e-18</td>\n",
       "      <td>1.824243e-16</td>\n",
       "      <td>-2.280304e-18</td>\n",
       "      <td>-9.121216e-18</td>\n",
       "      <td>7.296973e-17</td>\n",
       "      <td>9.121216e-17</td>\n",
       "      <td>-1.459395e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "      <td>1.000321e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.001285e+00</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.818064e-01</td>\n",
       "      <td>-1.839222e-01</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.425907e-01</td>\n",
       "      <td>-3.574600e-02</td>\n",
       "      <td>-8.842809e-02</td>\n",
       "      <td>-6.432184e-01</td>\n",
       "      <td>-1.610867e+00</td>\n",
       "      <td>-1.733044e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.001285e+00</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.818064e-01</td>\n",
       "      <td>-1.839222e-01</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.425907e-01</td>\n",
       "      <td>-3.574600e-02</td>\n",
       "      <td>-8.842809e-02</td>\n",
       "      <td>-6.432184e-01</td>\n",
       "      <td>-8.428132e-01</td>\n",
       "      <td>-8.653954e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.987171e-01</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.818064e-01</td>\n",
       "      <td>-1.839222e-01</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.425907e-01</td>\n",
       "      <td>-3.574600e-02</td>\n",
       "      <td>-8.842809e-02</td>\n",
       "      <td>-6.432184e-01</td>\n",
       "      <td>-3.635684e-02</td>\n",
       "      <td>2.996766e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.987171e-01</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.585174e-02</td>\n",
       "      <td>-2.818064e-01</td>\n",
       "      <td>-1.839222e-01</td>\n",
       "      <td>-2.534286e-02</td>\n",
       "      <td>-3.425907e-01</td>\n",
       "      <td>-3.574600e-02</td>\n",
       "      <td>-8.842809e-02</td>\n",
       "      <td>4.224971e-01</td>\n",
       "      <td>7.700996e-01</td>\n",
       "      <td>8.654553e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.987171e-01</td>\n",
       "      <td>2.789265e+01</td>\n",
       "      <td>2.789265e+01</td>\n",
       "      <td>3.945884e+01</td>\n",
       "      <td>3.945884e+01</td>\n",
       "      <td>2.789265e+01</td>\n",
       "      <td>2.789265e+01</td>\n",
       "      <td>3.945884e+01</td>\n",
       "      <td>3.945884e+01</td>\n",
       "      <td>2.789265e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.789265e+01</td>\n",
       "      <td>1.106839e+01</td>\n",
       "      <td>1.179686e+01</td>\n",
       "      <td>3.945884e+01</td>\n",
       "      <td>1.257104e+01</td>\n",
       "      <td>2.995240e+01</td>\n",
       "      <td>2.258712e+01</td>\n",
       "      <td>6.503345e+00</td>\n",
       "      <td>2.383012e+00</td>\n",
       "      <td>1.730881e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AWAY_GAME  SEASON_OPPONENT:atl:1996-97  SEASON_OPPONENT:atl:1997-98  \\\n",
       "count  1.558000e+03                 1.558000e+03                 1.558000e+03   \n",
       "mean   2.365815e-17                 1.368182e-17                 1.368182e-17   \n",
       "std    1.000321e+00                 1.000321e+00                 1.000321e+00   \n",
       "min   -1.001285e+00                -3.585174e-02                -3.585174e-02   \n",
       "25%   -1.001285e+00                -3.585174e-02                -3.585174e-02   \n",
       "50%    9.987171e-01                -3.585174e-02                -3.585174e-02   \n",
       "75%    9.987171e-01                -3.585174e-02                -3.585174e-02   \n",
       "max    9.987171e-01                 2.789265e+01                 2.789265e+01   \n",
       "\n",
       "       SEASON_OPPONENT:atl:1999-00  SEASON_OPPONENT:atl:2000-01  \\\n",
       "count                 1.558000e+03                 1.558000e+03   \n",
       "mean                  1.368182e-17                 9.121216e-18   \n",
       "std                   1.000321e+00                 1.000321e+00   \n",
       "min                  -2.534286e-02                -2.534286e-02   \n",
       "25%                  -2.534286e-02                -2.534286e-02   \n",
       "50%                  -2.534286e-02                -2.534286e-02   \n",
       "75%                  -2.534286e-02                -2.534286e-02   \n",
       "max                   3.945884e+01                 3.945884e+01   \n",
       "\n",
       "       SEASON_OPPONENT:atl:2001-02  SEASON_OPPONENT:atl:2002-03  \\\n",
       "count                 1.558000e+03                 1.558000e+03   \n",
       "mean                  9.121216e-18                 9.121216e-18   \n",
       "std                   1.000321e+00                 1.000321e+00   \n",
       "min                  -3.585174e-02                -3.585174e-02   \n",
       "25%                  -3.585174e-02                -3.585174e-02   \n",
       "50%                  -3.585174e-02                -3.585174e-02   \n",
       "75%                  -3.585174e-02                -3.585174e-02   \n",
       "max                   2.789265e+01                 2.789265e+01   \n",
       "\n",
       "       SEASON_OPPONENT:atl:2003-04  SEASON_OPPONENT:atl:2004-05  \\\n",
       "count                 1.558000e+03                 1.558000e+03   \n",
       "mean                  1.368182e-17                 1.368182e-17   \n",
       "std                   1.000321e+00                 1.000321e+00   \n",
       "min                  -2.534286e-02                -2.534286e-02   \n",
       "25%                  -2.534286e-02                -2.534286e-02   \n",
       "50%                  -2.534286e-02                -2.534286e-02   \n",
       "75%                  -2.534286e-02                -2.534286e-02   \n",
       "max                   3.945884e+01                 3.945884e+01   \n",
       "\n",
       "       SEASON_OPPONENT:atl:2005-06         ...          \\\n",
       "count                 1.558000e+03         ...           \n",
       "mean                  1.482198e-17         ...           \n",
       "std                   1.000321e+00         ...           \n",
       "min                  -3.585174e-02         ...           \n",
       "25%                  -3.585174e-02         ...           \n",
       "50%                  -3.585174e-02         ...           \n",
       "75%                  -3.585174e-02         ...           \n",
       "max                   2.789265e+01         ...           \n",
       "\n",
       "       ACTION_TYPE:tip_layup_shot  ACTION_TYPE:tip_shot  \\\n",
       "count                1.558000e+03          1.558000e+03   \n",
       "mean                -4.560608e-18         -4.560608e-17   \n",
       "std                  1.000321e+00          1.000321e+00   \n",
       "min                 -3.585174e-02         -2.818064e-01   \n",
       "25%                 -3.585174e-02         -2.818064e-01   \n",
       "50%                 -3.585174e-02         -2.818064e-01   \n",
       "75%                 -3.585174e-02         -2.818064e-01   \n",
       "max                  2.789265e+01          1.106839e+01   \n",
       "\n",
       "       ACTION_TYPE:turnaround_bank_shot  \\\n",
       "count                      1.558000e+03   \n",
       "mean                      -1.824243e-17   \n",
       "std                        1.000321e+00   \n",
       "min                       -1.839222e-01   \n",
       "25%                       -1.839222e-01   \n",
       "50%                       -1.839222e-01   \n",
       "75%                       -1.839222e-01   \n",
       "max                        1.179686e+01   \n",
       "\n",
       "       ACTION_TYPE:turnaround_fadeaway_bank_jump_shot  \\\n",
       "count                                    1.558000e+03   \n",
       "mean                                     9.121216e-18   \n",
       "std                                      1.000321e+00   \n",
       "min                                     -2.534286e-02   \n",
       "25%                                     -2.534286e-02   \n",
       "50%                                     -2.534286e-02   \n",
       "75%                                     -2.534286e-02   \n",
       "max                                      3.945884e+01   \n",
       "\n",
       "       ACTION_TYPE:turnaround_fadeaway_shot  \\\n",
       "count                          1.558000e+03   \n",
       "mean                           1.824243e-16   \n",
       "std                            1.000321e+00   \n",
       "min                           -3.425907e-01   \n",
       "25%                           -3.425907e-01   \n",
       "50%                           -3.425907e-01   \n",
       "75%                           -3.425907e-01   \n",
       "max                            1.257104e+01   \n",
       "\n",
       "       ACTION_TYPE:turnaround_finger_roll_shot  \\\n",
       "count                             1.558000e+03   \n",
       "mean                             -2.280304e-18   \n",
       "std                               1.000321e+00   \n",
       "min                              -3.574600e-02   \n",
       "25%                              -3.574600e-02   \n",
       "50%                              -3.574600e-02   \n",
       "75%                              -3.574600e-02   \n",
       "max                               2.995240e+01   \n",
       "\n",
       "       ACTION_TYPE:turnaround_hook_shot  ACTION_TYPE:turnaround_jump_shot  \\\n",
       "count                      1.558000e+03                      1.558000e+03   \n",
       "mean                      -9.121216e-18                      7.296973e-17   \n",
       "std                        1.000321e+00                      1.000321e+00   \n",
       "min                       -8.842809e-02                     -6.432184e-01   \n",
       "25%                       -8.842809e-02                     -6.432184e-01   \n",
       "50%                       -8.842809e-02                     -6.432184e-01   \n",
       "75%                       -8.842809e-02                      4.224971e-01   \n",
       "max                        2.258712e+01                      6.503345e+00   \n",
       "\n",
       "       SEASON_GAME_NUMBER  CAREER_GAME_NUMBER  \n",
       "count        1.558000e+03        1.558000e+03  \n",
       "mean         9.121216e-17       -1.459395e-16  \n",
       "std          1.000321e+00        1.000321e+00  \n",
       "min         -1.610867e+00       -1.733044e+00  \n",
       "25%         -8.428132e-01       -8.653954e-01  \n",
       "50%         -3.635684e-02        2.996766e-05  \n",
       "75%          7.700996e-01        8.654553e-01  \n",
       "max          2.383012e+00        1.730881e+00  \n",
       "\n",
       "[8 rows x 644 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = kobe.SHOTS_MADE.values\n",
    "X = kobe.iloc[:,1:]\n",
    "\n",
    "# Initialize the StandardScaler object\n",
    "\n",
    "\n",
    "ss = StandardScaler() \n",
    " \n",
    "# use the \"fit_transform\" function to normalize the X design matrix\n",
    "Xn = ss.fit_transform(X)\n",
    "\n",
    "Xnorm = pd.DataFrame(Xn, columns = X.columns)\n",
    "Xnorm\n",
    "\n",
    "# Normalization is necessary for regularized regression because the beta\n",
    "# values for each predictor variable must be on the same scale. If betas\n",
    "# are different sizes just because of the scale of predictor variables\n",
    "# the regularization term can't determine which betas are more/less \n",
    "# important based on their size.\n",
    "\n",
    "X.describe()\n",
    "Xnorm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Build a linear regression predicting `SHOTS_MADE` from the rest of the columns.\n",
    "\n",
    "Cross-validate the $R^2$ of a linear regression model with 10 cross-validation folds.\n",
    "\n",
    "How does it perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -6.87476575e+28  -4.45913757e+28  -2.44014351e+28  -1.68743375e+28\n",
      "  -3.53241289e+28]\n",
      "-3.79877869439e+28\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "#vanilla linear regression\n",
    "linreg_scores = cross_val_score(linreg, Xn, y, cv=5)\n",
    "# linreg.fit(Xn, y)\n",
    "# linreg.predict(Xn)\n",
    "# print \"score with normalization\"  + str(linreg.score(Xn, y))\n",
    "\n",
    "# linreg = LinearRegression()\n",
    "# linreg.fit(X, y)\n",
    "# linreg.predict(X)\n",
    "# print \"score without normalization\" + str(linreg.score(X, y))\n",
    "print linreg_scores\n",
    "print np.mean(linreg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The mean R^2 is extremely negative. All the R^2 scores are negative in crossvalidation.\n",
    "# The linear regression is performing far worse than baseline on the test sets.\n",
    "# It is probably dramatically overfitting and the redundant variables are affecting\n",
    "# the coefficients in weird ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Find an optimal value for Ridge regression alpha using RidgeCV\n",
    "\n",
    "[Go to the documentation and read how RidgeCV works.](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)\n",
    "\n",
    "Hint: once the RidgeCV is fit, the attribute `.alpha_` contains the best alpha parameter it found through cross-validation.\n",
    "\n",
    "Recall that Ridge performs best searching alphas through logarithmic space (`np.logspace`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559.081018251\n"
     ]
    }
   ],
   "source": [
    "ridge_alphas = np.logspace(0, 4, 100)\n",
    "\n",
    "optimal_ridge = RidgeCV(alphas=ridge_alphas, cv=5)\n",
    "optimal_ridge.fit(Xn, y)\n",
    "\n",
    "print optimal_ridge.alpha_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Cross-validate the Ridge $R^2$ with the optimal alpha.\n",
    "\n",
    "Is it better than the Linear regression? If so, why would this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68634538  0.56864065  0.535825    0.46270052  0.4989228 ]\n",
      "0.550486870073\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=optimal_ridge.alpha_)\n",
    "\n",
    "ridge_scores = cross_val_score(ridge, Xn, y, cv=5)\n",
    "\n",
    "print ridge_scores\n",
    "print np.mean(ridge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It's vastly better than the Linear Regression. \n",
    "# There is likely so much multicollinearity in the data that vanilla regression\n",
    "# can't do anything properly. Ridge is able to manage the multicollinearity\n",
    "# and get a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Find an optimal value for Lasso regression alpha using LassoCV\n",
    "\n",
    "[Go to the documentation and read how LassoCV works.](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) It is very similar to RidgeCV.\n",
    "\n",
    "Hint: again, once the LassoCV is fit, the attribute `.alpha_` contains the best alpha parameter it found through cross-validation.\n",
    "\n",
    "Recall that Lasso, unlike Ridge, performs best searching alphas through linear space (`np.linspace`). However, you can actually let the LassoCV decide itself what alphas to use by instead setting the keyword argument `n_alphas=` to however many alphas you want it to search over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0565473155307\n"
     ]
    }
   ],
   "source": [
    "optimal_lasso = LassoCV(n_alphas=100, cv=5, verbose=1)\n",
    "optimal_lasso.fit(Xn, y)\n",
    "\n",
    "print optimal_lasso.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Cross-validate the Lasso $R^2$ with the optimal alpha.\n",
    "\n",
    "Is it better than the Linear regression? Is it better than Ridge? For each, why would this be?\n",
    "\n",
    "Depending on which $R^2$ is better between the Ridge and Lasso, what can you infer about the primary issue in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.69484606  0.58808901  0.55314667  0.49096439  0.53620671]\n",
      "0.572650566506\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=optimal_lasso.alpha_)\n",
    "\n",
    "lasso_scores = cross_val_score(lasso, Xn, y, cv=5)\n",
    "\n",
    "print lasso_scores\n",
    "print np.mean(lasso_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The lasso performs slightly better than the Ridge, but similarly.\n",
    "# Lasso deals primarily with the feature selection of valuable variables,\n",
    "# eliminating ones that are not useful. This also takes care of multicollinearity,\n",
    "# but in a different way: it will choose the \"best\" of the correlated variables\n",
    "# and zero-out the other redundant ones.\n",
    "# There may also be useless variables in the data which it is simply getting rid\n",
    "# of entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Look at the coefficients for variables in the Lasso.\n",
    "\n",
    "1. Show the coefficient for variables, ordered from largest to smallest coefficient by absolute value.\n",
    "2. What percent of the variables in the original dataset are \"zeroed-out\" by the lasso?\n",
    "3. What are the most important predictors for how many shots kobe made in a game?\n",
    "\n",
    "Note: if you only fit the Lasso within cross_val_score, you will have to refit it outside of that\n",
    "function to pull out the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.056547315530653328, copy_X=True, fit_intercept=True,\n",
       "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(Xn, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_coef</th>\n",
       "      <th>coef</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>1.267017</td>\n",
       "      <td>1.267017</td>\n",
       "      <td>COMBINED_SHOT_TYPE:jump_shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0.828362</td>\n",
       "      <td>0.828362</td>\n",
       "      <td>SHOT_TYPE:2pt_field_goal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.469498</td>\n",
       "      <td>0.469498</td>\n",
       "      <td>SHOT_ZONE_BASIC:restricted_area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.283816</td>\n",
       "      <td>-0.283816</td>\n",
       "      <td>ACTION_TYPE:jump_shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>0.278567</td>\n",
       "      <td>0.278567</td>\n",
       "      <td>COMBINED_SHOT_TYPE:dunk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     abs_coef      coef                         variable\n",
       "579  1.267017  1.267017     COMBINED_SHOT_TYPE:jump_shot\n",
       "574  0.828362  0.828362         SHOT_TYPE:2pt_field_goal\n",
       "566  0.469498  0.469498  SHOT_ZONE_BASIC:restricted_area\n",
       "611  0.283816 -0.283816            ACTION_TYPE:jump_shot\n",
       "577  0.278567  0.278567          COMBINED_SHOT_TYPE:dunk"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lasso_coefs = pd.DataFrame({'variable':X.columns,\n",
    "                            'coef':lasso.coef_,\n",
    "                            'abs_coef':np.abs(lasso.coef_)})\n",
    "\n",
    "lasso_coefs.sort_values('abs_coef', inplace=True, ascending=False)\n",
    "\n",
    "lasso_coefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variables zeroed out: 0.304236200257\n"
     ]
    }
   ],
   "source": [
    "print 'Percent variables zeroed out:', np.sum((lasso.coef_ == 0))/float(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Find an optimal value for Elastic Net regression alpha using ElasticNetCV\n",
    "\n",
    "[Go to the documentation and read how LassoCV works.](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html).\n",
    "\n",
    "Note here that you will be optimizing both the alpha parameter and the l1_ratio:\n",
    "\n",
    "    alpha: strength of regularization\n",
    "    l1_ratio: amount of ridge vs. lasso (0 = all ridge, 1 = all lasso)\n",
    "    \n",
    "Do not include 0 in the search for l1_ratio: it will not allow it and break!\n",
    "\n",
    "You can use n_alphas for the alpha parameters instead of setting your own values: highly recommended!\n",
    "\n",
    "Also - be careful setting too many l1_ratios over cross-validation folds in your search. It can take a very long time if you choose too many combinations and for the most part there are diminishing returns in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................./Users/basilbeirouti/miniconda3/envs/dsienv/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:479: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      ".................................................................................[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0565473155307\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "l1_ratios = np.linspace(0.01, 1.0, 5)\n",
    "\n",
    "optimal_enet = ElasticNetCV(l1_ratio=l1_ratios, n_alphas=10, cv=5,\n",
    "                            verbose=1)\n",
    "optimal_enet.fit(Xn, y)\n",
    "\n",
    "print optimal_enet.alpha_\n",
    "print optimal_enet.l1_ratio_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Cross-validate the ElasticNet $R^2$ with the optimal alpha and l1_ratio.\n",
    "\n",
    "How does it compare to the other regularized regressions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.62359856  0.52594988  0.5373581   0.61516083  0.54289104  0.55459934\n",
      "  0.53103914  0.44676927  0.46403376  0.50827273]\n",
      "0.534967263327\n"
     ]
    }
   ],
   "source": [
    "enet = ElasticNet(alpha=optimal_enet.alpha_, l1_ratio=optimal_enet.l1_ratio_)\n",
    "\n",
    "enet_scores = cross_val_score(enet, Xn, y, cv=10)\n",
    "\n",
    "print enet_scores\n",
    "print np.mean(enet_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot the residuals for the ridge, lasso, and elastic net on histograms\n",
    "\n",
    "This is another way to look at the performance of your model.\n",
    "\n",
    "The tighter the distribution of residuals around zero, the better your model has performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to fit the ElasticNet and Ridge outside of cross_val_score like i did with the ridge\n",
    "ridge.fit(Xn, y)\n",
    "enet.fit(Xn, y)\n",
    "lasso.fit(Xn, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model residuals:\n",
    "\n",
    "ridge_resid = y - ridge.predict(Xn)\n",
    "lasso_resid = y - lasso.predict(Xn)\n",
    "enet_resid = y - enet.predict(Xn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "sns.distplot(ridge_resid, bins=50, hist=True, kde=False, \n",
    "             color='steelblue', ax=axarr[0], label='Ridge residuals')\n",
    "\n",
    "sns.distplot(lasso_resid, bins=50, hist=True, kde=False, \n",
    "             color='darkred', ax=axarr[1], label='Lasso residuals')\n",
    "\n",
    "sns.distplot(enet_resid, bins=50, hist=True, kde=False, \n",
    "             color='darkgoldenrod', ax=axarr[2], label='ElasticNet residuals')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsienv]",
   "language": "python",
   "name": "conda-env-dsienv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
